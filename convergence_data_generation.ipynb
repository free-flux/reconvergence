{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc49458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rethon import GlobalREEnsembleGenerator, ReflectiveEquilibrium, REState, StandardGlobalReflectiveEquilibrium\n",
    "from rethon.util import standard_model_params_varied_alphas\n",
    "from tau.util import create_random_argument_list\n",
    "from tau.util import random_position_as_set\n",
    "\n",
    "from tau import StandardPosition, DAGDialecticalStructure, DialecticalStructure, BitarrayPosition, BDDDialecticalStructure\n",
    "from tau.util import inferential_density\n",
    "\n",
    "from os import getcwd, path\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "\n",
    "from ast import literal_eval\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6958ad80",
   "metadata": {},
   "source": [
    "### Custom Ensemble Generator Class\n",
    "Excluding unused objects for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf0e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomREEnsembleGenerator(GlobalREEnsembleGenerator):\n",
    "    \n",
    "    def init_tau_fields(self, tau: DialecticalStructure):\n",
    "\n",
    "        self.add_obj('ds_infer_dens', inferential_density(tau))\n",
    "        #self.add_obj('n_premises', [len(arg) for arg in tau.get_arguments()])\n",
    "        #self.add_obj('principles', get_principles(tau.get_arguments()))\n",
    "        #tau_truths = tau.closure(BitarrayPosition(set(),\n",
    "                                                  #tau.sentence_pool().size()))\n",
    "        #self.add_obj('tau_truths', tau_truths)\n",
    "        #self.add_obj('tau_falsehoods', BitarrayPosition({-prop for prop in tau_truths.as_set()},\n",
    "                                                        #tau.sentence_pool().size()))    def init_re_start_fields(self, reflective_equilibrium: ReflectiveEquilibrium,\n",
    " \n",
    "            \n",
    "    def init_re_start_fields(self, reflective_equilibrium: ReflectiveEquilibrium,\n",
    "                             dialectical_structure: DialecticalStructure):\n",
    "\n",
    "        init_coms = reflective_equilibrium.state().initial_commitments()\n",
    "\n",
    "        #if dialectical_structure.is_consistent(init_coms):\n",
    "            #init_com_min_ax_bases = _get_min_sets([axioms.as_set() for axioms in\n",
    "                                                    #dialectical_structure.axioms(\n",
    "                                                    #init_coms,\n",
    "                                                    #init_coms.subpositions())])\n",
    "        #else:\n",
    "            #init_com_min_ax_bases = np.nan\n",
    "        #self.add_obj('init_com_min_ax_bases', init_com_min_ax_bases)\n",
    "        \n",
    "        # Global optima\n",
    "        global_optima = list(reflective_equilibrium.global_optima(init_coms))\n",
    "        self.add_obj('global_optima', global_optima)\n",
    "\n",
    "        # RE-states\n",
    "        re_states = {(theory, commitments) for (theory, commitments) in global_optima\n",
    "                     if dialectical_structure.is_consistent(BitarrayPosition.union({commitments, theory}))}\n",
    "        self.add_obj('re_states', re_states)\n",
    "\n",
    "        # full RE-states\n",
    "        full_re_states = {(theory, commitments) for (theory, commitments) in global_optima\n",
    "                          if dialectical_structure.closure(theory) == commitments}\n",
    "        self.add_obj('full_re_states', full_re_states)\n",
    "\n",
    "        \n",
    "    def init_ensemble_fields(self, ensemble_states: List[REState], dialectical_structure: DialecticalStructure):\n",
    "\n",
    "        self.add_obj('n_branches', len(ensemble_states))\n",
    "\n",
    "        # get all fixed_points of the process\n",
    "        branched_theories = [branch_state.last_theory() for branch_state in ensemble_states]\n",
    "        branched_commitments = [branch_state.last_commitments() for branch_state in ensemble_states]\n",
    "        fixed_points = list(Series(zip(branched_theories, branched_commitments)).unique())\n",
    "        self.add_obj('fixed_points', fixed_points)\n",
    "        \n",
    "    def init_re_final_fields(self, reflective_equilibrium: ReflectiveEquilibrium,\n",
    "                             dialectical_structure: DialecticalStructure):\n",
    "        pass\n",
    "    \n",
    "        #fp_comms_min_ax_bases = _fp_comms_min_ax_bases(dialectical_structure,\n",
    "                                                                    #reflective_equilibrium.state().last_commitments())\n",
    "        #self.add_obj('fixed_point_coms_min_ax_bases', fp_comms_min_ax_bases)\n",
    "        #fp_comms_min_ax_bases_th = _fp_comms_min_ax_bases_given_theory(dialectical_structure,\n",
    "                                                     #reflective_equilibrium.state().last_commitments(),\n",
    "                                                     #reflective_equilibrium.state().last_theory())\n",
    "        #self.add_obj('fixed_point_coms_min_ax_bases_theory', fp_comms_min_ax_bases_th)\n",
    "        \n",
    "        # remove unused fields from ensemble generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "711c8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_remove_list = [#'model_name'\n",
    "                    #'ds',\n",
    "                    #'n_sentence_pool',\n",
    "                    'ds_arg_size',\n",
    "                    #'ds_infer_dens',\n",
    "                    #'ds_n_consistent_complete_positions',\n",
    "                    'ds_mean_prem',\n",
    "                    'ds_variance_prem',\n",
    "                    'tau_truths',\n",
    "                    'principles',\n",
    "                    #'account_penalties',\n",
    "                    #'faithfulness_penalties',\n",
    "                    #'weight_account',\n",
    "                    #'weight_systematicity',\n",
    "                    #'weight_faithfulness',\n",
    "                    #'init_coms',\n",
    "                    'init_coms_size',\n",
    "                    'init_coms_n_tau_truths',\n",
    "                    'init_coms_n_tau_falsehoods',\n",
    "                    'init_coms_n_consistent_complete_positions',\n",
    "                    #'init_coms_dia_consistent',\n",
    "                    'init_coms_closed',\n",
    "                    #'fixed_point_coms',\n",
    "                    'fixed_point_coms_size',\n",
    "                    'fixed_point_coms_n_tau_truths',\n",
    "                    'fixed_point_coms_n_tau_falsehoods',\n",
    "                    'fixed_point_coms_closed',\n",
    "                    #'fixed_point_coms_consistent',\n",
    "                    'fixed_point_coms_n_consistent_complete_positions',\n",
    "                    #'fixed_point_theory',\n",
    "                    'fixed_point_theory_closure',\n",
    "                    'init_coms_min_ax_bases',\n",
    "                    'n_init_coms_min_ax_base',\n",
    "                    'achievements_evolution',\n",
    "                    #'fixed_point_dia_consistent',\n",
    "                    'init_final_coms_simple_hamming',\n",
    "                    'init_final_coms_hamming',\n",
    "                    'init_final_coms_contradictions',\n",
    "                    'init_final_coms_expansions',\n",
    "                    'init_final_coms_contractions',\n",
    "                    'init_final_coms_identities',\n",
    "                    'random_choices',\n",
    "                    'n_random_choices',\n",
    "                    'coms_evolution',\n",
    "                    'theory_evolution',\n",
    "                    'process_length',\n",
    "                    #'n_branches',\n",
    "                    #'fixed_points',\n",
    "                    #'n_fixed_points',\n",
    "                    #'fp_coms_consistent',\n",
    "                    #'fp_union_consistent',\n",
    "                    'fp_account',\n",
    "                    'fp_faithfulness',\n",
    "                    #'fixed_point_is_global_optimum',\n",
    "                    #'fixed_point_is_re_state',\n",
    "                    #'fixed_point_is_full_re_state',\n",
    "                    #'global_optima',\n",
    "                    #'n_global_optima',\n",
    "                    #'go_coms_consistent',\n",
    "                    #'go_union_consistent',\n",
    "                    #'go_full_re_state',\n",
    "                    'go_account',\n",
    "                    'go_faithfulness',\n",
    "                    're_states',\n",
    "                    'n_re_states',\n",
    "                    #'full_re_states',\n",
    "                    #'n_full_re_states',\n",
    "                    'fixed_point_coms_min_ax_bases',\n",
    "                    'n_fixed_point_coms_min_ax_base',\n",
    "                    'fixed_point_coms_min_ax_bases_theory',\n",
    "                    'n_fixed_point_coms_min_ax_base_theory',\n",
    "                    'fixed_point_theory_axioms',\n",
    "                    #'go_fixed_point',\n",
    "                    #'fp_full_re_state',\n",
    "                    #'fp_global_optimum'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7637f27e",
   "metadata": {},
   "source": [
    "### Ensemble Generation: Convergence - Full Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "addee339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3], [1, 4], [1, 5], [1, -6], [2, -4], [2, 5], [2, 6], [2, 7]]\n",
      "0.26143928550824114\n"
     ]
    }
   ],
   "source": [
    "# sentence pool\n",
    "n = 7\n",
    "\n",
    "# standard example\n",
    "arguments = [[1, 3],[1, 4],[1, 5],[1, -6], [2, -4],[2, 5],[2, 6],[2, 7]]\n",
    "\n",
    "\n",
    "arguments_list = [arguments]\n",
    "\n",
    "dia = DAGDialecticalStructure(n, arguments)\n",
    "\n",
    "\n",
    "print(arguments)\n",
    "print(inferential_density(dia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bea7bd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments for each dialectical structure\n",
    "arguments_list = [arguments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b65a9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2186\n"
     ]
    }
   ],
   "source": [
    "# full spectrum of commitments\n",
    "coms_list = [pos.as_set() for pos in dia.minimally_consistent_positions() if pos.size()]\n",
    "print(len(coms_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa94566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "configurations = [\n",
    "                  [0.35, 0.55, 0.10],\n",
    "                  #[0.55, 0.35, 0.10],\n",
    "                  #[0.70, 0.20, 0.10],\n",
    "                  #[0.55, 0.20, 0.25],\n",
    "                  #[0.46, 0.10, 0.44],\n",
    "                  #[0.10, 0.55, 0.35],\n",
    "                  #[0.10, 0.35, 0.55],\n",
    "                  ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_parameters_list = []\n",
    "\n",
    "for configuration in configurations:\n",
    "    model_parameters = StandardGlobalReflectiveEquilibrium.default_model_parameters()\n",
    "    \n",
    "    model_parameters[\"weights\"][\"account\"] = configuration[0]\n",
    "    model_parameters[\"weights\"][\"systematicity\"] = configuration[1]\n",
    "    model_parameters[\"weights\"][\"faithfulness\"] = configuration[2]\n",
    "    \n",
    "    model_parameters_list.append(model_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91c2d217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'weights': {'account': 0.35, 'systematicity': 0.55, 'faithfulness': 0.1},\n",
       "  'account_penalties': [0.0, 0.3, 1.0, 1.0],\n",
       "  'faithfulness_penalties': [0.0, 0.0, 1.0, 1.0]},\n",
       " {'weights': {'account': 0.55, 'systematicity': 0.35, 'faithfulness': 0.1},\n",
       "  'account_penalties': [0.0, 0.3, 1.0, 1.0],\n",
       "  'faithfulness_penalties': [0.0, 0.0, 1.0, 1.0]},\n",
       " {'weights': {'account': 0.7, 'systematicity': 0.2, 'faithfulness': 0.1},\n",
       "  'account_penalties': [0.0, 0.3, 1.0, 1.0],\n",
       "  'faithfulness_penalties': [0.0, 0.0, 1.0, 1.0]},\n",
       " {'weights': {'account': 0.55, 'systematicity': 0.2, 'faithfulness': 0.25},\n",
       "  'account_penalties': [0.0, 0.3, 1.0, 1.0],\n",
       "  'faithfulness_penalties': [0.0, 0.0, 1.0, 1.0]},\n",
       " {'weights': {'account': 0.46, 'systematicity': 0.1, 'faithfulness': 0.44},\n",
       "  'account_penalties': [0.0, 0.3, 1.0, 1.0],\n",
       "  'faithfulness_penalties': [0.0, 0.0, 1.0, 1.0]},\n",
       " {'weights': {'account': 0.1, 'systematicity': 0.55, 'faithfulness': 0.35},\n",
       "  'account_penalties': [0.0, 0.3, 1.0, 1.0],\n",
       "  'faithfulness_penalties': [0.0, 0.0, 1.0, 1.0]},\n",
       " {'weights': {'account': 0.1, 'systematicity': 0.35, 'faithfulness': 0.55},\n",
       "  'account_penalties': [0.0, 0.3, 1.0, 1.0],\n",
       "  'faithfulness_penalties': [0.0, 0.0, 1.0, 1.0]}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e1a94a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard example\n",
    "\n",
    "# default implementation:\n",
    "implementations = [{'tau_module_name': 'tau',\n",
    "                    'position_class_name':'StandardPosition',\n",
    "                    'dialectical_structure_class_name': 'DAGDialecticalStructure',\n",
    "                    'rethon_module_name': 'rethon',\n",
    "                    'reflective_equilibrium_class_name': 'StandardGlobalReflectiveEquilibrium'}]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "ensemble_gen = CustomREEnsembleGenerator(arguments_list = arguments_list, \n",
    "                                     n_sentence_pool = n,\n",
    "                                     initial_commitments_list = coms_list,\n",
    "                                     model_parameters_list = model_parameters_list,\n",
    "                                     implementations = implementations,\n",
    "                                     create_branches = True)\n",
    "# remove unused fields\n",
    "for item in item_remove_list:\n",
    "    ensemble_gen.remove_item(item)\n",
    "\n",
    "\n",
    "\n",
    "ensemble_gen.ensemble_items_to_csv(\n",
    "                              output_file_name = 'data_full_spectrum_convergence_std_ex.csv',\n",
    "                              output_dir_name = path.join(getcwd(), \"data\"),\n",
    "                              archive = True, # save the csv as archived tar.gz\n",
    "                              save_preliminary_results = True, # will create preliminary csv-data sets \n",
    "                              preliminary_results_interval = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca81890a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6, -1, -4], [5, 7, 6], [-3, 2, 6], [-7, 1], [1, -5, -6], [-6, -4, -5], [5, -3]]\n",
      "[[2, -3], [4, 3], [-6, 7, 2], [-5, -3], [2, -6, 3], [-1, 4, -5], [-4, 7]]\n",
      "[[1, -7], [-6, -2, -1], [3, 4, -6], [6, 7, -2], [-2, 5, 1], [-1, 7]]\n",
      "[[-3, -6], [1, -7, -3], [4, -2, 6], [3, -2, 7], [-7, 5, 3], [-2, 6], [1, -4]]\n",
      "[[3, 2], [5, -2], [1, -2], [-4, -5], [7, -6, -4]]\n",
      "[[6, -7, 5], [-3, -5], [1, 5], [2, -7], [4, 3], [4, -2, -5], [7, -6, 1], [2, -6]]\n",
      "[[-5, 2, -7], [4, 6, -7], [-1, -3, 6], [4, 5, -6], [2, 6]]\n",
      "[[-6, 1], [-5, 7, -6], [-3, -7], [-2, -5], [7, 4, 1], [-2, 1]]\n",
      "[[-7, -5], [3, -1, 5], [2, 7], [-6, -7], [4, -3], [-7, 3]]\n",
      "[[-3, -1, -2], [7, 5, -3], [-6, -1], [-4, -7], [2, -3]]\n"
     ]
    }
   ],
   "source": [
    "# random dialectical structures\n",
    "\n",
    "n=7\n",
    "\n",
    "for i in range(21,31):\n",
    "    \n",
    "    # one dialectical structure in inferential density range\n",
    "    while True:\n",
    "\n",
    "        arguments = create_random_argument_list(n_arguments_min=n-2, n_arguments_max=n+1,\n",
    "                                    n_sentences=n, n_premises_max=2)\n",
    "        \n",
    "        dia = BDDDialecticalStructure(n, arguments)\n",
    "        \n",
    "        # check inferential density and usage of all sentences\n",
    "        if (0.15<=inferential_density(dia)<=0.5) and (len(set(abs(s) for arg in arguments for s in arg))==n):\n",
    "            \n",
    "            # ensure that there are no tau-truths\n",
    "            if dia.closure(StandardPosition.from_set(set(), 3)).size()==0:\n",
    "            \n",
    "                arguments_list = [arguments]\n",
    "                print(arguments)\n",
    "                break\n",
    "            \n",
    "    # default implementation:\n",
    "    implementations = [{'tau_module_name': 'tau',\n",
    "                        'position_class_name':'StandardPosition',\n",
    "                        'dialectical_structure_class_name': 'DAGDialecticalStructure',\n",
    "                        'rethon_module_name': 'rethon',\n",
    "                        'reflective_equilibrium_class_name': 'StandardGlobalReflectiveEquilibrium'}]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ensemble_gen = CustomREEnsembleGenerator(arguments_list = arguments_list, \n",
    "                                         n_sentence_pool = n,\n",
    "                                         initial_commitments_list = coms_list,\n",
    "                                         model_parameters_list = model_parameters_list,\n",
    "                                         implementations = implementations,\n",
    "                                         create_branches = True)\n",
    "    # remove unused fields\n",
    "    for item in item_remove_list:\n",
    "        ensemble_gen.remove_item(item)\n",
    "\n",
    "\n",
    "\n",
    "    ensemble_gen.ensemble_items_to_csv(\n",
    "                                  output_file_name = 'data_full_spectrum_convergence_rand_ex_'+str(i)+ '.csv',\n",
    "                                  output_dir_name = path.join(getcwd(), \"data\"),\n",
    "                                  archive = True, # save the csv as archived tar.gz\n",
    "                                  save_preliminary_results = True, # will create preliminary csv-data sets \n",
    "                                  preliminary_results_interval = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febad163",
   "metadata": {},
   "source": [
    "### Adding Additional Weight Configurations to Existing Full Spectrum Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20869912",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = path.join(getcwd(), \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ea5b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['model_name', 'ds', 'n_sentence_pool', 'ds_infer_dens',\n",
      "       'ds_n_consistent_complete_positions', 'account_penalties',\n",
      "       'faithfulness_penalties', 'weight_account', 'weight_systematicity',\n",
      "       'weight_faithfulness', 'init_coms', 'init_coms_dia_consistent',\n",
      "       'fixed_point_coms', 'fixed_point_coms_consistent', 'fixed_point_theory',\n",
      "       'fixed_point_dia_consistent', 'n_branches', 'fixed_points',\n",
      "       'n_fixed_points', 'fp_coms_consistent', 'fp_union_consistent',\n",
      "       'fixed_point_is_global_optimum', 'fixed_point_is_re_state',\n",
      "       'fixed_point_is_full_re_state', 'global_optima', 'n_global_optima',\n",
      "       'go_coms_consistent', 'go_union_consistent', 'go_full_re_state',\n",
      "       'full_re_states', 'n_full_re_states', 'go_fixed_point',\n",
      "       'fp_full_re_state', 'fp_global_optimum', 'configuration'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(327900, 35)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "\n",
    "data_file_name = 'data_full_spectrum_convergence_rand_ex_all_configs.csv.tar.gz'\n",
    "\n",
    "if data_file_name[data_file_name.find('.'):len(data_file_name)] == '.csv.tar.gz':\n",
    "    with tarfile.open(path.join(data_dir,data_file_name)) as tar:\n",
    "        for tarinfo in tar:\n",
    "            file_name = tarinfo.name\n",
    "        tar.extractall(data_dir)\n",
    "    re_data = pd.read_csv(path.join(data_dir, file_name))\n",
    "\n",
    "else:\n",
    "    re_data = pd.read_csv(path.join(data_dir,data_file_name))\n",
    "\n",
    "print(re_data.columns)\n",
    "re_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cfccb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters for loop below\n",
    "configurations = [#[0.35, 0.55, 0.10],\n",
    "                  #[0.55, 0.35, 0.10],\n",
    "                  #[0.70, 0.20, 0.10],\n",
    "                  #[0.55, 0.20, 0.25],\n",
    "                  #[0.46, 0.10, 0.44],\n",
    "                  [0.10, 0.55, 0.35],\n",
    "                  [0.10, 0.35, 0.55],\n",
    "                  ]\n",
    "\n",
    "model_parameters_list = []\n",
    "\n",
    "for configuration in configurations:\n",
    "    model_parameters = StandardGlobalReflectiveEquilibrium.default_model_parameters()\n",
    "    \n",
    "    model_parameters[\"weights\"][\"account\"] = configuration[0]\n",
    "    model_parameters[\"weights\"][\"systematicity\"] = configuration[1]\n",
    "    model_parameters[\"weights\"][\"faithfulness\"] = configuration[2]\n",
    "    \n",
    "    model_parameters_list.append(model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba448bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2186\n"
     ]
    }
   ],
   "source": [
    "# full spectrum of commitments\n",
    "coms_list = [pos.as_set() for pos in dia.minimally_consistent_positions() if pos.size()]\n",
    "print(len(coms_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f3b6ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# all dialectical structures\n",
    "arguments_list = [literal_eval(ds) for ds in re_data[\"ds\"].unique()]\n",
    "print(len(arguments_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bebf3839",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8adcf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default implementation:\n",
    "implementations = [{'tau_module_name': 'tau',\n",
    "                    'position_class_name':'StandardPosition',\n",
    "                    'dialectical_structure_class_name': 'DAGDialecticalStructure',\n",
    "                    'rethon_module_name': 'rethon',\n",
    "                    'reflective_equilibrium_class_name': 'StandardGlobalReflectiveEquilibrium'}]\n",
    "\n",
    "ensemble_gen = CustomREEnsembleGenerator(arguments_list = arguments_list, \n",
    "                                     n_sentence_pool = n,\n",
    "                                     initial_commitments_list = coms_list,\n",
    "                                     model_parameters_list = model_parameters_list,\n",
    "                                     implementations = implementations,\n",
    "                                     create_branches = True)\n",
    "\n",
    "# remove unused fields\n",
    "for item in item_remove_list:\n",
    "    ensemble_gen.remove_item(item)\n",
    "    \n",
    "ensemble_gen.ensemble_items_to_csv(\n",
    "                              output_file_name = 'data_full_spectrum_convergence_rand_ex_add_config2.csv',\n",
    "                              output_dir_name = path.join(getcwd(), \"data\"),\n",
    "                              archive = True, # save the csv as archived tar.gz\n",
    "                              save_preliminary_results = True, # will create preliminary csv-data sets \n",
    "                              preliminary_results_interval = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31570da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['model_name', 'ds', 'n_sentence_pool', 'ds_infer_dens',\n",
      "       'ds_n_consistent_complete_positions', 'account_penalties',\n",
      "       'faithfulness_penalties', 'weight_account', 'weight_systematicity',\n",
      "       'weight_faithfulness', 'init_coms', 'init_coms_dia_consistent',\n",
      "       'fixed_point_coms', 'fixed_point_coms_consistent', 'fixed_point_theory',\n",
      "       'fixed_point_dia_consistent', 'n_branches', 'fixed_points',\n",
      "       'n_fixed_points', 'fp_coms_consistent', 'fp_union_consistent',\n",
      "       'fixed_point_is_global_optimum', 'fixed_point_is_re_state',\n",
      "       'fixed_point_is_full_re_state', 'global_optima', 'n_global_optima',\n",
      "       'go_coms_consistent', 'go_union_consistent', 'go_full_re_state',\n",
      "       'full_re_states', 'n_full_re_states', 'go_fixed_point',\n",
      "       'fp_full_re_state', 'fp_global_optimum', 'configuration'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(327900, 35)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "\n",
    "data_file_name = 'data_full_spectrum_convergence_rand_ex_all_configs.csv.tar.gz'\n",
    "\n",
    "if data_file_name[data_file_name.find('.'):len(data_file_name)] == '.csv.tar.gz':\n",
    "    with tarfile.open(path.join(data_dir,data_file_name)) as tar:\n",
    "        for tarinfo in tar:\n",
    "            file_name = tarinfo.name\n",
    "        tar.extractall(data_dir)\n",
    "    re_data = pd.read_csv(path.join(data_dir, file_name))\n",
    "\n",
    "else:\n",
    "    re_data = pd.read_csv(path.join(data_dir,data_file_name))\n",
    "\n",
    "print(re_data.columns)\n",
    "re_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ef57deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['model_name', 'ds', 'n_sentence_pool', 'ds_infer_dens',\n",
      "       'ds_n_consistent_complete_positions', 'account_penalties',\n",
      "       'faithfulness_penalties', 'weight_account', 'weight_systematicity',\n",
      "       'weight_faithfulness', 'init_coms', 'init_coms_dia_consistent',\n",
      "       'fixed_point_coms', 'fixed_point_coms_consistent', 'fixed_point_theory',\n",
      "       'fixed_point_dia_consistent', 'n_branches', 'fixed_points',\n",
      "       'n_fixed_points', 'fp_coms_consistent', 'fp_union_consistent',\n",
      "       'fixed_point_is_global_optimum', 'fixed_point_is_re_state',\n",
      "       'fixed_point_is_full_re_state', 'global_optima', 'n_global_optima',\n",
      "       'go_coms_consistent', 'go_union_consistent', 'go_full_re_state',\n",
      "       'full_re_states', 'n_full_re_states', 'go_fixed_point',\n",
      "       'fp_full_re_state', 'fp_global_optimum'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(131160, 34)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "\n",
    "data_file_name = 'data_full_spectrum_convergence_rand_ex_add_config2.csv.tar.gz'\n",
    "\n",
    "if data_file_name[data_file_name.find('.'):len(data_file_name)] == '.csv.tar.gz':\n",
    "    with tarfile.open(path.join(data_dir,data_file_name)) as tar:\n",
    "        for tarinfo in tar:\n",
    "            file_name = tarinfo.name\n",
    "        tar.extractall(data_dir)\n",
    "    re_data2 = pd.read_csv(path.join(data_dir, file_name))\n",
    "\n",
    "else:\n",
    "    re_data2 = pd.read_csv(path.join(data_dir,data_file_name))\n",
    "\n",
    "print(re_data2.columns)\n",
    "re_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0d14e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_data3 = pd.concat([re_data, re_data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "367ed611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(459060, 35)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_data3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ace2357e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_account</th>\n",
       "      <th>weight_systematicity</th>\n",
       "      <th>ds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.35</td>\n",
       "      <td>65580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.55</td>\n",
       "      <td>65580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.55</td>\n",
       "      <td>65580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.10</td>\n",
       "      <td>65580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.20</td>\n",
       "      <td>65580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.35</td>\n",
       "      <td>65580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.20</td>\n",
       "      <td>65580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_account  weight_systematicity     ds\n",
       "0            0.10                  0.35  65580\n",
       "1            0.10                  0.55  65580\n",
       "2            0.35                  0.55  65580\n",
       "3            0.46                  0.10  65580\n",
       "4            0.55                  0.20  65580\n",
       "5            0.55                  0.35  65580\n",
       "6            0.70                  0.20  65580"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_data3.groupby([\"weight_account\", \"weight_systematicity\"])[\"ds\"].size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb5e7bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = path.join(getcwd(), \"data\")\n",
    "file_name=\"data_full_spectrum_convergence_rand_ex_all_configs2.csv\"\n",
    "\n",
    "# write results to a .csv.file\n",
    "re_data3.to_csv(path.join(data_dir, file_name), index=False)\n",
    "\n",
    "# add to a tar file\n",
    "tar_file = path.join(data_dir, file_name + '.tar.gz')\n",
    "with tarfile.open(tar_file, \"w:gz\") as tar:\n",
    "    tar.add(path.join(data_dir, file_name), recursive=False, arcname=file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3afc290",
   "metadata": {},
   "source": [
    "## Ensemble Generation: Two Point Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b4fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters for loop below\n",
    "configurations = [[0.35, 0.55, 0.10],\n",
    "                  #[0.55, 0.35, 0.10],\n",
    "                  #[0.70, 0.20, 0.10],\n",
    "                  #[0.55, 0.20, 0.25],\n",
    "                  #[0.46, 0.10, 0.44],\n",
    "                  #[0.10, 0.55, 0.35],\n",
    "                  #[0.10, 0.35, 0.55],\n",
    "                  ]\n",
    "\n",
    "model_parameters_list = []\n",
    "\n",
    "for configuration in configurations:\n",
    "    model_parameters = StandardGlobalReflectiveEquilibrium.default_model_parameters()\n",
    "    \n",
    "    model_parameters[\"weights\"][\"account\"] = configuration[0]\n",
    "    model_parameters[\"weights\"][\"systematicity\"] = configuration[1]\n",
    "    model_parameters[\"weights\"][\"faithfulness\"] = configuration[2]\n",
    "    \n",
    "    model_parameters_list.append(model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0157f1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "n_dia_structures = 400\n",
    "\n",
    "\n",
    "for n_sentence_pool in [9]:\n",
    "    \n",
    "    print(n_sentence_pool)\n",
    "\n",
    "    # loop\n",
    "    for j in range(n_dia_structures):\n",
    "\n",
    "        arguments_list = []\n",
    "\n",
    "        # one dialectical structure in inferential density range\n",
    "        while True:\n",
    "\n",
    "            arguments = create_random_argument_list(n_arguments_min=n_sentence_pool-2,\n",
    "                                                    n_arguments_max=n_sentence_pool+1,\n",
    "                                                    n_sentences=n_sentence_pool, \n",
    "                                                    n_premises_max=2)\n",
    "\n",
    "            dia = DAGDialecticalStructure(n_sentence_pool, arguments)\n",
    "\n",
    "            # check inferential density and usage of all sentences\n",
    "            if (0.15<=inferential_density(dia)<=0.5) and (len(set(abs(s) for arg in arguments for s in arg))==n_sentence_pool):\n",
    "                arguments_list = [arguments]\n",
    "                #print(arguments)\n",
    "                break\n",
    "\n",
    "        coms_list = []\n",
    "\n",
    "        while not coms_list:\n",
    "\n",
    "            init_coms1 = StandardPosition.from_set(random_position_as_set(n_sentence_pool), n_sentence_pool)\n",
    "            init_coms2 = StandardPosition.from_set(random_position_as_set(n_sentence_pool), n_sentence_pool)\n",
    "\n",
    "            # ensure non-identical initial committments\n",
    "            if init_coms1 != init_coms2:\n",
    "\n",
    "                coms_list = [init_coms1.as_set(), init_coms2.as_set()]\n",
    "\n",
    "        # default implementation:\n",
    "        implementations = [{'tau_module_name': 'tau',\n",
    "                            'position_class_name':'StandardPosition',\n",
    "                            'dialectical_structure_class_name': 'DAGDialecticalStructure',\n",
    "                            'rethon_module_name': 'rethon',\n",
    "                            'reflective_equilibrium_class_name': 'StandardGlobalReflectiveEquilibrium'}]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ensemble_gen = CustomREEnsembleGenerator(arguments_list = arguments_list, \n",
    "                                             n_sentence_pool = n_sentence_pool,\n",
    "                                             initial_commitments_list = coms_list,\n",
    "                                             model_parameters_list = model_parameters_list,\n",
    "                                             implementations = implementations,\n",
    "                                             create_branches = True)\n",
    "        # remove unused fields\n",
    "        for item in item_remove_list:\n",
    "            ensemble_gen.remove_item(item)\n",
    "\n",
    "\n",
    "\n",
    "        ensemble_gen.ensemble_items_to_csv(\n",
    "                                      output_file_name = 'data_two_point_convergence_sp_'+str(n_sentence_pool)+'_05.csv',\n",
    "                                      output_dir_name = path.join(getcwd(), \"data\"),\n",
    "                                      archive = False, # save the csv as archived tar.gz\n",
    "                                      save_preliminary_results = True, # will create preliminary csv-data sets \n",
    "                                      preliminary_results_interval = 100,\n",
    "                                      append = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c9d5d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenation and saving as tar file\n",
    "import tarfile\n",
    "from itertools import product\n",
    "\n",
    "data_dir = path.join(getcwd(), \"data\")\n",
    "\n",
    "dfs = []\n",
    "for file_name in [\"data_two_point_convergence_sp_{}_{}.csv\".format(i,j) \n",
    "                  for (i,j) in product(range(6,10), [\"0{}\".format(i) for i in range(6)])]:\n",
    "\n",
    "    dfs.append(pd.read_csv(path.join(data_dir, file_name)))\n",
    "\n",
    "re_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "file_name = \"data_two_point_convergence_sp_6789_00.csv\"\n",
    "\n",
    "re_data.to_csv(path.join(data_dir, file_name), index=False)\n",
    "\n",
    "tar_file = path.join(data_dir, file_name + '.tar.gz')\n",
    "with tarfile.open(tar_file, \"w:gz\") as tar:\n",
    "    tar.add(path.join(data_dir, file_name), recursive=False, arcname=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b535cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfe39953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence pool\n",
    "n = 7\n",
    "\n",
    "# standard example\n",
    "arguments = [[1, 3],[1, 4],[1, 5],[1, -6], [2, -4],[2, 5],[2, 6],[2, 7]]\n",
    "\n",
    "\n",
    "arguments_list = [arguments]\n",
    "\n",
    "dia = BDDDialecticalStructure(n, arguments)\n",
    "re= StandardGlobalReflectiveEquilibrium(dia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d53c00f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b78c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters for loop below\n",
    "configurations = [[0.35, 0.55, 0.10],\n",
    "                  #[0.55, 0.35, 0.10],\n",
    "                  #[0.70, 0.20, 0.10],\n",
    "                  #[0.55, 0.20, 0.25],\n",
    "                  #[0.46, 0.10, 0.44],\n",
    "                  #[0.10, 0.55, 0.35],\n",
    "                  #[0.10, 0.35, 0.55],\n",
    "                  ]\n",
    "\n",
    "model_parameters_list = []\n",
    "\n",
    "for configuration in configurations:\n",
    "    model_parameters = StandardGlobalReflectiveEquilibrium.default_model_parameters()\n",
    "    \n",
    "    model_parameters[\"weights\"][\"account\"] = configuration[0]\n",
    "    model_parameters[\"weights\"][\"systematicity\"] = configuration[1]\n",
    "    model_parameters[\"weights\"][\"faithfulness\"] = configuration[2]\n",
    "    \n",
    "    model_parameters_list.append(model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fc4be11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n"
     ]
    }
   ],
   "source": [
    "n_sentence_pool=7\n",
    "\n",
    "min_init_coms_size = floor(n_sentence_pool/2)\n",
    "\n",
    "n_pairs = 50\n",
    "\n",
    "pair_list = []\n",
    "\n",
    "for target_hamming_dist in range(1,2*n_sentence_pool):\n",
    "    \n",
    "    min_init_coms_size = max(round(target_hamming_dist/2, 0), min_init_coms_size)\n",
    "\n",
    "    for _ in range(n_pairs):\n",
    "        \n",
    "        coms_list = []\n",
    "        \n",
    "        while not coms_list:\n",
    "\n",
    "                    init_coms1 = StandardPosition.from_set(random_position_as_set(n_sentence_pool), n_sentence_pool)\n",
    "\n",
    "                    if init_coms1.size()>=min_init_coms_size:\n",
    "                        #print(init_coms1.size())\n",
    "\n",
    "                        init_coms2 = StandardPosition.from_set(random_position_as_set(n_sentence_pool), n_sentence_pool)\n",
    "\n",
    "                        if init_coms2.size()>=min_init_coms_size:\n",
    "                            #print(init_coms2.size())\n",
    "\n",
    "                            # ensure non-identical initial committments\n",
    "                            if re.hamming_distance (init_coms1, init_coms2, [0,1,1,2])==target_hamming_dist:\n",
    "\n",
    "                                coms_list = [init_coms1.as_set(), init_coms2.as_set()]\n",
    "                                \n",
    "                                pair_list.append(coms_list)\n",
    "                                #print(coms_list, target_hamming_dist)\n",
    "\n",
    "\n",
    "print(len(pair_list))\n",
    "\n",
    "for i, coms_list in enumerate(pair_list):\n",
    "    \n",
    "        print(i)\n",
    "        # one dialectical structure in inferential density range\n",
    "        while True:\n",
    "\n",
    "            arguments = create_random_argument_list(n_arguments_min=n_sentence_pool-2,\n",
    "                                                    n_arguments_max=n_sentence_pool+1,\n",
    "                                                    n_sentences=n_sentence_pool, \n",
    "                                                    n_premises_max=2)\n",
    "\n",
    "            dia = DAGDialecticalStructure(n_sentence_pool, arguments)\n",
    "\n",
    "            # check inferential density and usage of all sentences\n",
    "            if (0.15<=inferential_density(dia)<=0.5) and (len(set(abs(s) for arg in arguments for s in arg))==n_sentence_pool):\n",
    "                arguments_list = [arguments]\n",
    "                #print(arguments)\n",
    "                break\n",
    "\n",
    "        \n",
    "\n",
    "        # default implementation:\n",
    "        implementations = [{'tau_module_name': 'tau',\n",
    "                            'position_class_name':'StandardPosition',\n",
    "                            'dialectical_structure_class_name': 'DAGDialecticalStructure',\n",
    "                            'rethon_module_name': 'rethon',\n",
    "                            'reflective_equilibrium_class_name': 'StandardGlobalReflectiveEquilibrium'}]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ensemble_gen = CustomREEnsembleGenerator(arguments_list = arguments_list, \n",
    "                                             n_sentence_pool = n_sentence_pool,\n",
    "                                             initial_commitments_list = coms_list,\n",
    "                                             model_parameters_list = model_parameters_list,\n",
    "                                             implementations = implementations,\n",
    "                                             create_branches = True)\n",
    "        # remove unused fields\n",
    "        for item in item_remove_list:\n",
    "            ensemble_gen.remove_item(item)\n",
    "\n",
    "\n",
    "\n",
    "        ensemble_gen.ensemble_items_to_csv(\n",
    "                                      output_file_name = 'data_two_point_convergence_binned_sp_'+str(n_sentence_pool)+'_018.csv',\n",
    "                                      output_dir_name = path.join(getcwd(), \"data\"),\n",
    "                                      archive = False, # save the csv as archived tar.gz\n",
    "                                      save_preliminary_results = True, # will create preliminary csv-data sets \n",
    "                                      preliminary_results_interval = 100,\n",
    "                                      append = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3fd87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ee6c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenation and saving as tar file\n",
    "import tarfile\n",
    "from itertools import product\n",
    "\n",
    "data_dir = path.join(getcwd(), \"data\")\n",
    "\n",
    "dfs = []\n",
    "for file_name in [\"data_two_point_convergence_binned_sp_7_0{}.csv\".format(i) \n",
    "                  for i in range(19)]:\n",
    "\n",
    "    dfs.append(pd.read_csv(path.join(data_dir, file_name)))\n",
    "\n",
    "re_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "file_name = \"data_two_point_convergence_binned_sp_7.csv\"\n",
    "\n",
    "re_data.to_csv(path.join(data_dir, file_name), index=False)\n",
    "\n",
    "tar_file = path.join(data_dir, file_name + '.tar.gz')\n",
    "with tarfile.open(tar_file, \"w:gz\") as tar:\n",
    "    tar.add(path.join(data_dir, file_name), recursive=False, arcname=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07ad60f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965e7a4f",
   "metadata": {},
   "source": [
    "### Additional Configuration of Weights For Existing \"Two-Point\" Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae7ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = path.join(getcwd(), \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7b2c375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['model_name', 'ds', 'n_sentence_pool', 'ds_infer_dens',\n",
      "       'ds_n_consistent_complete_positions', 'account_penalties',\n",
      "       'faithfulness_penalties', 'weight_account', 'weight_systematicity',\n",
      "       'weight_faithfulness', 'init_coms', 'init_coms_dia_consistent',\n",
      "       'fixed_point_coms', 'fixed_point_coms_consistent', 'fixed_point_theory',\n",
      "       'fixed_point_dia_consistent', 'n_branches', 'fixed_points',\n",
      "       'n_fixed_points', 'fp_coms_consistent', 'fp_union_consistent',\n",
      "       'fixed_point_is_global_optimum', 'fixed_point_is_re_state',\n",
      "       'fixed_point_is_full_re_state', 'global_optima', 'n_global_optima',\n",
      "       'go_coms_consistent', 'go_union_consistent', 'go_full_re_state',\n",
      "       'full_re_states', 'n_full_re_states', 'go_fixed_point',\n",
      "       'fp_full_re_state', 'fp_global_optimum', 'configuration'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afrei\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (34) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(130000, 35)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "\n",
    "data_file_name = 'data_two_point_convergence_binned_sp_7_all_configs.csv.tar.gz'\n",
    "\n",
    "if data_file_name[data_file_name.find('.'):len(data_file_name)] == '.csv.tar.gz':\n",
    "    with tarfile.open(path.join(data_dir,data_file_name)) as tar:\n",
    "        for tarinfo in tar:\n",
    "            file_name = tarinfo.name\n",
    "        tar.extractall(data_dir)\n",
    "    re_data = pd.read_csv(path.join(data_dir, file_name))\n",
    "\n",
    "else:\n",
    "    re_data = pd.read_csv(path.join(data_dir,data_file_name))\n",
    "\n",
    "print(re_data.columns)\n",
    "re_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ef139d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    13000.0\n",
       "mean         2.0\n",
       "std          0.0\n",
       "min          2.0\n",
       "25%          2.0\n",
       "50%          2.0\n",
       "75%          2.0\n",
       "max          2.0\n",
       "Name: init_coms, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_data.groupby(\"ds\")[\"init_coms\"].nunique().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7349e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters for loop below\n",
    "configurations = [#[0.35, 0.55, 0.10],\n",
    "                  #[0.55, 0.35, 0.10],\n",
    "                  #[0.70, 0.20, 0.10],\n",
    "                  #[0.55, 0.20, 0.25],\n",
    "                  #[0.46, 0.10, 0.44],\n",
    "                  [0.10, 0.55, 0.35],\n",
    "                  [0.10, 0.35, 0.55],\n",
    "                  ]\n",
    "\n",
    "model_parameters_list = []\n",
    "\n",
    "for configuration in configurations:\n",
    "    model_parameters = StandardGlobalReflectiveEquilibrium.default_model_parameters()\n",
    "    \n",
    "    model_parameters[\"weights\"][\"account\"] = configuration[0]\n",
    "    model_parameters[\"weights\"][\"systematicity\"] = configuration[1]\n",
    "    model_parameters[\"weights\"][\"faithfulness\"] = configuration[2]\n",
    "    \n",
    "    model_parameters_list.append(model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "234e69f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f2d4c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sentence_pool = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "301c5918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12999\n"
     ]
    }
   ],
   "source": [
    "for i, ds in enumerate(re_data[\"ds\"].unique()):\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(i)\n",
    "\n",
    "    \n",
    "    arguments_list = []\n",
    "    arguments_list.append(literal_eval(ds))\n",
    "    \n",
    "    coms_list = []\n",
    "    \n",
    "    for coms in re_data[re_data[\"ds\"]==ds][\"init_coms\"].unique():\n",
    "        coms_list.append(literal_eval(coms))\n",
    "\n",
    "    # default implementation:\n",
    "    implementations = [{'tau_module_name': 'tau',\n",
    "                        'position_class_name':'StandardPosition',\n",
    "                        'dialectical_structure_class_name': 'DAGDialecticalStructure',\n",
    "                        'rethon_module_name': 'rethon',\n",
    "                        'reflective_equilibrium_class_name': 'StandardGlobalReflectiveEquilibrium'}]\n",
    "    \n",
    "    ensemble_gen = CustomREEnsembleGenerator(arguments_list = arguments_list, \n",
    "                                             n_sentence_pool = n_sentence_pool,\n",
    "                                             initial_commitments_list = coms_list,\n",
    "                                             model_parameters_list = model_parameters_list,\n",
    "                                             implementations = implementations,\n",
    "                                             create_branches = True)\n",
    "    # remove unused fields\n",
    "    for item in item_remove_list:\n",
    "        ensemble_gen.remove_item(item)\n",
    "        \n",
    "    ensemble_gen.ensemble_items_to_csv(\n",
    "                                      output_file_name = 'data_two_point_convergence_binned_sp_7_add_config.csv',\n",
    "                                      output_dir_name = path.join(getcwd(), \"data\"),\n",
    "                                      archive = False, # save the csv as archived tar.gz\n",
    "                                      save_preliminary_results = True, # will create preliminary csv-data sets \n",
    "                                      preliminary_results_interval = 500,\n",
    "                                      append = True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6e35867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['model_name', 'ds', 'n_sentence_pool', 'ds_infer_dens',\n",
      "       'ds_n_consistent_complete_positions', 'account_penalties',\n",
      "       'faithfulness_penalties', 'weight_account', 'weight_systematicity',\n",
      "       'weight_faithfulness', 'init_coms', 'init_coms_dia_consistent',\n",
      "       'fixed_point_coms', 'fixed_point_coms_consistent', 'fixed_point_theory',\n",
      "       'fixed_point_dia_consistent', 'n_branches', 'fixed_points',\n",
      "       'n_fixed_points', 'fp_coms_consistent', 'fp_union_consistent',\n",
      "       'fixed_point_is_global_optimum', 'fixed_point_is_re_state',\n",
      "       'fixed_point_is_full_re_state', 'global_optima', 'n_global_optima',\n",
      "       'go_coms_consistent', 'go_union_consistent', 'go_full_re_state',\n",
      "       'full_re_states', 'n_full_re_states', 'go_fixed_point',\n",
      "       'fp_full_re_state', 'fp_global_optimum', 'configuration'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afrei\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (34) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(130000, 35)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "\n",
    "data_file_name = 'data_two_point_convergence_binned_sp_7_all_configs.csv.tar.gz'\n",
    "\n",
    "if data_file_name[data_file_name.find('.'):len(data_file_name)] == '.csv.tar.gz':\n",
    "    with tarfile.open(path.join(data_dir,data_file_name)) as tar:\n",
    "        for tarinfo in tar:\n",
    "            file_name = tarinfo.name\n",
    "        tar.extractall(data_dir)\n",
    "    re_data = pd.read_csv(path.join(data_dir, file_name))\n",
    "\n",
    "else:\n",
    "    re_data = pd.read_csv(path.join(data_dir,data_file_name))\n",
    "\n",
    "print(re_data.columns)\n",
    "re_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eed86e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['model_name', 'ds', 'n_sentence_pool', 'ds_infer_dens',\n",
      "       'ds_n_consistent_complete_positions', 'account_penalties',\n",
      "       'faithfulness_penalties', 'weight_account', 'weight_systematicity',\n",
      "       'weight_faithfulness', 'init_coms', 'init_coms_dia_consistent',\n",
      "       'fixed_point_coms', 'fixed_point_coms_consistent', 'fixed_point_theory',\n",
      "       'fixed_point_dia_consistent', 'n_branches', 'fixed_points',\n",
      "       'n_fixed_points', 'fp_coms_consistent', 'fp_union_consistent',\n",
      "       'fixed_point_is_global_optimum', 'fixed_point_is_re_state',\n",
      "       'fixed_point_is_full_re_state', 'global_optima', 'n_global_optima',\n",
      "       'go_coms_consistent', 'go_union_consistent', 'go_full_re_state',\n",
      "       'full_re_states', 'n_full_re_states', 'go_fixed_point',\n",
      "       'fp_full_re_state', 'fp_global_optimum'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(52000, 34)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "\n",
    "data_file_name = 'data_two_point_convergence_binned_sp_7_add_config.csv'\n",
    "\n",
    "if data_file_name[data_file_name.find('.'):len(data_file_name)] == '.csv.tar.gz':\n",
    "    with tarfile.open(path.join(data_dir,data_file_name)) as tar:\n",
    "        for tarinfo in tar:\n",
    "            file_name = tarinfo.name\n",
    "        tar.extractall(data_dir)\n",
    "    re_data2 = pd.read_csv(path.join(data_dir, file_name))\n",
    "\n",
    "else:\n",
    "    re_data2 = pd.read_csv(path.join(data_dir,data_file_name))\n",
    "\n",
    "print(re_data2.columns)\n",
    "re_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e0c220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "re_data3 = pd.concat([re_data, re_data2], ignore_index=True)\n",
    "\n",
    "file_name = \"data_two_point_convergence_binned_sp_7_all_configs2.csv\"\n",
    "\n",
    "re_data3.to_csv(path.join(data_dir, file_name), index=False)\n",
    "\n",
    "tar_file = path.join(data_dir, file_name + '.tar.gz')\n",
    "with tarfile.open(tar_file, \"w:gz\") as tar:\n",
    "    tar.add(path.join(data_dir, file_name), recursive=False, arcname=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc655d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
