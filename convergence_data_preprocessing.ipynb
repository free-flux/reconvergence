{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e174cbf",
   "metadata": {},
   "source": [
    "# Two Point Convergence Study: Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5a2db1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b0ed0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tau import StandardPosition, DAGDialecticalStructure, BDDDialecticalStructure\n",
    "from rethon import StandardGlobalReflectiveEquilibrium\n",
    "\n",
    "from tau.util import inferential_density\n",
    "\n",
    "from itertools import product, combinations, chain\n",
    "from random import choice\n",
    "\n",
    "from os import getcwd, path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55f559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4e141",
   "metadata": {},
   "source": [
    "### Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd327395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def literal_eval_cols(data: DataFrame, cols: List[str]):\n",
    "    for col_name in cols:\n",
    "        data[col_name] = data.apply(lambda x: literal_eval(x[col_name]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f84d57ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_agreement(pos1, pos2, re):\n",
    "    \"\"\"Adapted to partial positions from Betz (2013, 39)\"\"\" \n",
    "    \n",
    "    n = re.dialectical_structure().sentence_pool().size()\n",
    "    \n",
    "    return 1 - ( re.hamming_distance(pos1, pos2, [0,1,1,2]) / (2*n) )\n",
    "    #return 1 - ( re.hamming_distance(pos1, pos2, [0,1,1,1]) / n )\n",
    "    \n",
    "    \n",
    "def similarity_list(group1, group2, re):\n",
    "    similarity_list = []\n",
    "    \n",
    "    for pos1 in group1:\n",
    "        for pos2 in group2:\n",
    "            similarity_list.append(normalized_agreement(pos1, pos2, re))\n",
    "            \n",
    "    return similarity_list\n",
    "\n",
    "    \n",
    "def group_normalized_agreement(group1, group2, re):\n",
    "    \"\"\"Mean normalized agreement between two groups of positions. \n",
    "    Corresponds to normalized agreement if both groups have length 1.\"\"\"\n",
    "    agreement = 0\n",
    "    \n",
    "    for pos1 in group1:\n",
    "        for pos2 in group2:\n",
    "            agreement += normalized_agreement(pos1, pos2, re)\n",
    "    \n",
    "    # average\n",
    "    agreement /= (len(group1) * len(group2))\n",
    "        \n",
    "    return agreement\n",
    "\n",
    "def population_normalized_agreement(population, re):\n",
    "    \"\"\"Debate-wide mean normalized agreement from Betz (2013, 40) adapted to partial positions\"\"\"\n",
    "    agreement = 0\n",
    "    counter = 0\n",
    "    \n",
    "    for pos1, pos2 in combinations(population, 2):\n",
    "    \n",
    "        agreement += normalized_agreement(pos1, pos2, re)\n",
    "        counter += 1\n",
    "    \n",
    "    # average\n",
    "    agreement /= counter\n",
    "        \n",
    "    return agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f556c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_compatibility(group1, group2, re):\n",
    "    \"\"\"\"\"\"\n",
    "    compatibility = 0\n",
    "\n",
    "    for pos1 in group1:\n",
    "        for pos2 in group2:\n",
    "            \n",
    "            if re.dialectical_structure().are_compatible(pos1, pos2):\n",
    "                compatibility += 1\n",
    "    \n",
    "    # average\n",
    "    compatibility /= (len(group1) * len(group2))\n",
    "        \n",
    "    return compatibility\n",
    "\n",
    "def compatibility_list(group1, group2, re):\n",
    "    \"\"\"\"\"\"\n",
    "    compatibility_list = []\n",
    "    \n",
    "    for pos1 in group1:\n",
    "        for pos2 in group2:\n",
    "            \n",
    "            if re.dialectical_structure().are_compatible(pos1, pos2):\n",
    "                compatibility_list.append(1)\n",
    "            else:\n",
    "                compatibility_list.append(0)\n",
    "        \n",
    "    return compatibility_list\n",
    "\n",
    "def population_compatibility(population, re):\n",
    "    \"\"\"\"\"\"\n",
    "    compatibility = 0\n",
    "    counter = 0\n",
    "        \n",
    "    for pos1, pos2 in combinations(population, 2):\n",
    "        counter +=1\n",
    "            \n",
    "        if re.dialectical_structure().are_compatible(pos1, pos2):\n",
    "            compatibility += 1\n",
    "    \n",
    "    # average\n",
    "    compatibility /= counter\n",
    "        \n",
    "    return compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78a3c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility for streamlined output\n",
    "def get_remainders(dia, position):\n",
    "    if dia.is_consistent(position):\n",
    "        return [position]\n",
    "    \n",
    "    # find remainders\n",
    "    remainders = [subpos for subpos in position.subpositions() if dia.is_consistent(subpos)]\n",
    "        \n",
    "    #find all max remainders\n",
    "    max_remainders = []\n",
    "    max_length = 0\n",
    "    for remainder in remainders:\n",
    "\n",
    "        if remainder.size() > max_length:\n",
    "            max_remainders = [remainder]\n",
    "            max_length = remainder.size()\n",
    "            \n",
    "        elif remainder.size() == max_length:\n",
    "\n",
    "            max_remainders.append(remainder)\n",
    "            \n",
    "    return max_remainders\n",
    "\n",
    "def get_streamlined_output(dia, init_coms):\n",
    "    \n",
    "    remainders=get_remainders(dia, init_coms)\n",
    "    \n",
    "    outputs = []    \n",
    "    for remainder in remainders:\n",
    "        # axiomatization of remainder with subpositions as source\n",
    "        for mab in dia.axioms(remainder, remainder.subpositions()):\n",
    "            outputs.append((mab, dia.closure(mab)))\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86409533",
   "metadata": {},
   "source": [
    "## Preprocessing Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33e2e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = path.join(getcwd(), \"data\")\n",
    "#data_file_name = 'data_two_point_convergence_binned_sp__7_00.csv.tar.gz'\n",
    "data_file_name = 'data_two_point_convergence_binned_sp_7_all_configs.csv.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "211aa76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['model_name', 'ds', 'n_sentence_pool', 'ds_infer_dens',\n",
      "       'ds_n_consistent_complete_positions', 'account_penalties',\n",
      "       'faithfulness_penalties', 'weight_account', 'weight_systematicity',\n",
      "       'weight_faithfulness', 'init_coms', 'init_coms_dia_consistent',\n",
      "       'fixed_point_coms', 'fixed_point_coms_consistent', 'fixed_point_theory',\n",
      "       'fixed_point_dia_consistent', 'n_branches', 'fixed_points',\n",
      "       'n_fixed_points', 'fp_coms_consistent', 'fp_union_consistent',\n",
      "       'fixed_point_is_global_optimum', 'fixed_point_is_re_state',\n",
      "       'fixed_point_is_full_re_state', 'global_optima', 'n_global_optima',\n",
      "       'go_coms_consistent', 'go_union_consistent', 'go_full_re_state',\n",
      "       'full_re_states', 'n_full_re_states', 'go_fixed_point',\n",
      "       'fp_full_re_state', 'fp_global_optimum', 'configuration'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(130000, 35)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "\n",
    "\n",
    "if data_file_name[data_file_name.find('.'):len(data_file_name)] == '.csv.tar.gz':\n",
    "    with tarfile.open(path.join(data_dir,data_file_name)) as tar:\n",
    "        for tarinfo in tar:\n",
    "            file_name = tarinfo.name\n",
    "        tar.extractall(data_dir)\n",
    "    re_data = pd.read_csv(path.join(data_dir, file_name))\n",
    "\n",
    "else:\n",
    "    re_data = pd.read_csv(path.join(data_dir,data_file_name))\n",
    "\n",
    "print(re_data.columns)\n",
    "re_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "702f243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "literal_eval_cols(re_data, [\"fixed_points\", \"global_optima\", \"fp_full_re_state\", \"go_full_re_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1844e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_data[\"configuration\"] = re_data.apply(lambda row: (row[\"weight_account\"], \n",
    "                                                      row[\"weight_systematicity\"], \n",
    "                                                      row[\"weight_faithfulness\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9143548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df = re_data[['n_sentence_pool', \"ds\", \"configuration\", \"init_coms\", \"fixed_points\", \"fp_full_re_state\"]]\n",
    "\n",
    "#go_df = re_data[['n_sentence_pool', \"ds\", \"configuration\", \"init_coms\", \"global_optima\", \"go_full_re_state\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3fbaa0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130000, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4b94706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_df[\"ds\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a136de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df[\"fixed_points_lengths\"] = fp_df.apply(lambda row: [(len(fp[0]), len(fp[1])) \n",
    "                                                                       for fp in row[\"fixed_points\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caee63f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230780, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explode fixed point information\n",
    "ex_fp_df = fp_df.set_index(['n_sentence_pool', \"ds\", \"configuration\", \"init_coms\"]).apply(pd.Series.explode).reset_index()\n",
    "ex_fp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c101a996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80851, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restrict to full RE fixed points\n",
    "ex_fp_df = ex_fp_df[ex_fp_df[\"fp_full_re_state\"]]\n",
    "ex_fp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55dfe4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78976, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restrict further to non-trivial full RE fixed points\n",
    "ex_fp_df = ex_fp_df[ex_fp_df[\"fixed_points_lengths\"]!=(1,1)]\n",
    "ex_fp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85ec72f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of unique initial commitments that yield non-trivial full RE fixed point\n",
    "# per dialectical structure and configuration\n",
    "ex_fp_df_grouped = ex_fp_df.groupby([\"ds\", \"configuration\"])[\"init_coms\"].nunique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d73acee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33510, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select pairs of simulation setups that both yield at least one non-trivial full RE fixed point\n",
    "ffull_re_fp_df = fp_df.merge(ex_fp_df_grouped[ex_fp_df_grouped[\"init_coms\"]==2][[\"ds\", \"configuration\"]], \n",
    "                         on=[\"ds\", \"configuration\"], how=\"inner\")\n",
    "ffull_re_fp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58f86e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df[\"any_nontrivial_full_re_fixed_point\"] = fp_df.apply(lambda row: any([pair[0] and pair[1]!=(1,1) \n",
    "                                                                           for pair in zip(row[\"fp_full_re_state\"], row[\"fixed_points_lengths\"])]),\n",
    "                                                          axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53a66ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61055"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_df[\"any_nontrivial_full_re_fixed_point\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1f519c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is there any full RE fixed point per simulation setup?\n",
    "#fp_df[\"any_fp_full_re_state\"] = fp_df[\"fp_full_re_state\"].apply(any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "809b14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df_grouped = fp_df.groupby(['n_sentence_pool', \"ds\", \"configuration\"]).aggregate({\"any_nontrivial_full_re_fixed_point\":all}).reset_index()\n",
    "#fp_df_grouped = fp_df.groupby(['n_sentence_pool', \"ds\", \"configuration\"]).aggregate({\"any_fp_full_re_state\":all}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ff49e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33510, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select pairs of simulation setups that both yield at least one full RE fixed point\n",
    "full_re_fp_df = fp_df.merge(fp_df_grouped[fp_df_grouped[\"any_nontrivial_full_re_fixed_point\"]][[\"ds\", \"configuration\"]], \n",
    "                         on=[\"ds\", \"configuration\"], how=\"inner\")\n",
    "full_re_fp_df.shape\n",
    "\n",
    "# select pairs of simulation setups that both yield at least one full RE fixed point\n",
    "#full_re_fp_df = fp_df.merge(fp_df_grouped[fp_df_grouped[\"any_fp_full_re_state\"]][[\"ds\", \"configuration\"]], \n",
    "#                         on=[\"ds\", \"configuration\"], how=\"inner\")\n",
    "#full_re_fp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a6311cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep full RE fixed points\n",
    "full_re_fp_df[\"full_re_fixed_points\"] = full_re_fp_df.apply(lambda row: [pair[0] \n",
    "                                                                         for pair in zip(row[\"fixed_points\"], row[\"fp_full_re_state\"]) if pair[1]], axis=1)\n",
    "\n",
    "# only keep full RE fixed points\n",
    "full_re_fp_df[\"full_re_fixed_points_lengths\"] = full_re_fp_df.apply(lambda row: [pair[0] for pair in zip(row[\"fixed_points_lengths\"], row[\"fp_full_re_state\"]) if pair[1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "159a0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_re_fp_df.drop([\"any_nontrivial_full_re_fixed_point\", \"fixed_points\",\"fixed_points_lengths\", \"fp_full_re_state\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b52f6de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33510, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_re_fp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3263f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_re_fp_df[\"full_re_fp_lenghts\"] = full_re_fp_df.apply(lambda row: [(len(fp[0]), len(fp[1])) \n",
    "#                                                                       for fp in row[\"full_re_fixed_points\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a7538b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_re_fp_df[\"any_fp_nontrivial\"] = full_re_fp_df.apply(lambda row: any([fp_len!=(1,1) \n",
    "#                                                                         for fp_len in row[\"full_re_fixed_points\"]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d6fcfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_re_fp_df[\"any_fp_nontrivial\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49a992dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_re_fp_df_grouped = full_re_fp_df.groupby(['n_sentence_pool', \"ds\", \"configuration\"]).aggregate({\"any_fp_nontrivial\":all}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40d93b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select pairs of simulation setups that both yield a nontrivial RE fixed point\n",
    "#nontrivial_full_re_fp_df = fp_df.merge(full_re_fp_df_grouped[full_re_fp_df_grouped[\"any_fp_nontrivial\"]][[\"ds\", \"configuration\"]], \n",
    "#                         on=[\"ds\", \"configuration\"], how=\"inner\")\n",
    "#nontrivial_full_re_fp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d394b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nontrivial_full_re_fp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a98b0923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nontrivial_full_re_fp_df.drop([\"any_fp_nontrivial\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf75d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ex_fp_df = nontrivial_full_re_fp_df.set_index(['n_sentence_pool', \"ds\", \"configuration\", \"init_coms\"]).apply(pd.Series.explode).reset_index()\n",
    "#print(ex_fp_df.shape)\n",
    "#ex_go_df = go_df.set_index(['n_sentence_pool', \"ds\", \"configuration\", \"init_coms\"]).apply(pd.Series.explode).reset_index()\n",
    "#print(ex_go_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cfeb34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43663, 6)\n"
     ]
    }
   ],
   "source": [
    "ex_fp_df = full_re_fp_df.set_index(['n_sentence_pool', \"ds\", \"configuration\", \"init_coms\"]).apply(pd.Series.explode).reset_index()\n",
    "print(ex_fp_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92ed75e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_sentence_pool</th>\n",
       "      <th>ds</th>\n",
       "      <th>configuration</th>\n",
       "      <th>init_coms</th>\n",
       "      <th>full_re_fixed_points</th>\n",
       "      <th>full_re_fixed_points_lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>[[-2, 7, 1], [-4, 2], [5, 1], [3, 6, 5], [4, 3...</td>\n",
       "      <td>(0.55, 0.35, 0.1)</td>\n",
       "      <td>{-7, -5, -4, -3, -2}</td>\n",
       "      <td>({-1, 6}, {2, 6, -5, -4, -3, -1})</td>\n",
       "      <td>(2, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>[[-2, 7, 1], [-4, 2], [5, 1], [3, 6, 5], [4, 3...</td>\n",
       "      <td>(0.55, 0.35, 0.1)</td>\n",
       "      <td>{-7, -4, -3, -2}</td>\n",
       "      <td>({-3}, {2, -4, -3})</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>[[-2, 7, 1], [-4, 2], [5, 1], [3, 6, 5], [4, 3...</td>\n",
       "      <td>(0.46, 0.1, 0.44)</td>\n",
       "      <td>{-7, -5, -4, -3, -2}</td>\n",
       "      <td>({-7, -1, 6}, {2, 6, -7, -5, -4, -3, -1})</td>\n",
       "      <td>(3, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>[[-2, 7, 1], [-4, 2], [5, 1], [3, 6, 5], [4, 3...</td>\n",
       "      <td>(0.46, 0.1, 0.44)</td>\n",
       "      <td>{-7, -4, -3, -2}</td>\n",
       "      <td>({-7, -3}, {-7, 2, -4, -3})</td>\n",
       "      <td>(2, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[[7, -6, -2], [-5, -4, 2], [-3, -1, -6], [-1, ...</td>\n",
       "      <td>(0.46, 0.1, 0.44)</td>\n",
       "      <td>{7, -2, -4, -3, -1}</td>\n",
       "      <td>({-4, -2, 7}, {3, 5, 6, 7, -2, -4, -1})</td>\n",
       "      <td>(3, 7)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_sentence_pool                                                 ds  \\\n",
       "0                7  [[-2, 7, 1], [-4, 2], [5, 1], [3, 6, 5], [4, 3...   \n",
       "1                7  [[-2, 7, 1], [-4, 2], [5, 1], [3, 6, 5], [4, 3...   \n",
       "2                7  [[-2, 7, 1], [-4, 2], [5, 1], [3, 6, 5], [4, 3...   \n",
       "3                7  [[-2, 7, 1], [-4, 2], [5, 1], [3, 6, 5], [4, 3...   \n",
       "4                7  [[7, -6, -2], [-5, -4, 2], [-3, -1, -6], [-1, ...   \n",
       "\n",
       "       configuration             init_coms  \\\n",
       "0  (0.55, 0.35, 0.1)  {-7, -5, -4, -3, -2}   \n",
       "1  (0.55, 0.35, 0.1)      {-7, -4, -3, -2}   \n",
       "2  (0.46, 0.1, 0.44)  {-7, -5, -4, -3, -2}   \n",
       "3  (0.46, 0.1, 0.44)      {-7, -4, -3, -2}   \n",
       "4  (0.46, 0.1, 0.44)   {7, -2, -4, -3, -1}   \n",
       "\n",
       "                        full_re_fixed_points full_re_fixed_points_lengths  \n",
       "0          ({-1, 6}, {2, 6, -5, -4, -3, -1})                       (2, 6)  \n",
       "1                        ({-3}, {2, -4, -3})                       (1, 3)  \n",
       "2  ({-7, -1, 6}, {2, 6, -7, -5, -4, -3, -1})                       (3, 7)  \n",
       "3                ({-7, -3}, {-7, 2, -4, -3})                       (2, 4)  \n",
       "4    ({-4, -2, 7}, {3, 5, 6, 7, -2, -4, -1})                       (3, 7)  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_fp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bfc37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict exploded data frame to full RE states\n",
    "#ex_fp_df = ex_fp_df[ex_fp_df[\"fp_full_re_state\"]]\n",
    "#print(ex_fp_df.shape)\n",
    "#ex_go_df = ex_go_df[ex_go_df[\"go_full_re_state\"]]\n",
    "#print(ex_go_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4858476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    16755.0\n",
       "mean         2.0\n",
       "std          0.0\n",
       "min          2.0\n",
       "25%          2.0\n",
       "50%          2.0\n",
       "75%          2.0\n",
       "max          2.0\n",
       "Name: init_coms, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether there are at least 2 different initial commitments per structure and configuration left\n",
    "ex_fp_df.groupby([\"ds\", \"configuration\"])[\"init_coms\"].nunique().reset_index()[\"init_coms\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cbf48a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>configuration</th>\n",
       "      <th>full_re_fixed_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.35, 0.55, 0.1)</td>\n",
       "      <td>5458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.46, 0.1, 0.44)</td>\n",
       "      <td>16205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.55, 0.2, 0.25)</td>\n",
       "      <td>7368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.55, 0.35, 0.1)</td>\n",
       "      <td>10216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.7, 0.2, 0.1)</td>\n",
       "      <td>4416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       configuration  full_re_fixed_points\n",
       "0  (0.35, 0.55, 0.1)                  5458\n",
       "1  (0.46, 0.1, 0.44)                 16205\n",
       "2  (0.55, 0.2, 0.25)                  7368\n",
       "3  (0.55, 0.35, 0.1)                 10216\n",
       "4    (0.7, 0.2, 0.1)                  4416"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_fp_df.groupby([\"configuration\"])[\"full_re_fixed_points\"].size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0999e7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n_sentence_pool', 'ds', 'configuration', 'init_coms',\n",
       "       'full_re_fixed_points', 'full_re_fixed_points_lengths'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_fp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c371cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "ex_fp_df.columns = ['n_sentence_pool', 'ds', 'configuration', 'init_coms',\n",
    "       'fixed_points', 'full_re_fixed_points_lengths']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179fdfe3",
   "metadata": {},
   "source": [
    "### Streamlined outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8fa1a85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18916, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# streamlined outputs\n",
    "so_df = ex_fp_df.drop_duplicates(['n_sentence_pool', \"ds\", \"init_coms\"])\n",
    "so_df.drop([\"configuration\", \"fixed_points\",  'full_re_fixed_points_lengths'], inplace=True, axis=1)\n",
    "so_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26515128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n_sentence_pool', 'ds', 'init_coms'], dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e2f39cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "so_df[\"streamlined_output\"] = so_df.apply(lambda row: get_streamlined_output(BDDDialecticalStructure(row['n_sentence_pool'], literal_eval(row[\"ds\"])),\n",
    "                                                                        StandardPosition.from_set(literal_eval(row[\"init_coms\"]), row['n_sentence_pool'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5038924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['n_sentence_pool', 'ds', 'init_coms', 'streamlined_output'], dtype='object')\n",
      "(18916, 4)\n"
     ]
    }
   ],
   "source": [
    "print(so_df.columns)\n",
    "print(so_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f94c46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27946, 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_so_df = so_df.set_index(['n_sentence_pool', \"ds\", \"init_coms\"]).apply(pd.Series.explode).reset_index()\n",
    "ex_so_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "983b76da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    18916.000000\n",
       "mean         1.477374\n",
       "std          0.784441\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          1.000000\n",
       "75%          2.000000\n",
       "max          9.000000\n",
       "Name: streamlined_output, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall number of streamlined outputs reached from individual commitments\n",
    "so_df[\"streamlined_output\"].map(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3edae8",
   "metadata": {},
   "source": [
    "### Additional data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb5dded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "afcd5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for args in ex_fp_df[\"ds\"].unique():\n",
    "    \n",
    "    n =ex_fp_df[ex_fp_df[\"ds\"]==args][\"n_sentence_pool\"].unique()[0]\n",
    "    \n",
    "    dia = BDDDialecticalStructure(n, literal_eval(args))\n",
    "    re = StandardGlobalReflectiveEquilibrium(dia)\n",
    "    \n",
    "    result_row = {}\n",
    "    result_row[\"ds\"] = args\n",
    "    result_row[\"n\"] = n\n",
    "    result_row[\"infer_dens\"] = inferential_density(dia)\n",
    "    \n",
    "    # restrict dataframes to dialectical structure\n",
    "    sub_ex_fp_df = ex_fp_df[(ex_fp_df[\"ds\"]==args)]\n",
    "    #sub_ex_go_df = ex_go_df[(ex_go_df[\"ds\"]==args)]\n",
    "    sub_ex_so_df = ex_so_df[(ex_so_df[\"ds\"]==args)]\n",
    "    \n",
    "    # initial commitments (identical for fp, go and so)\n",
    "    init_coms = [StandardPosition.from_set(literal_eval(coms), n) for coms in sub_ex_fp_df[\"init_coms\"].unique()]\n",
    "    \n",
    "\n",
    "    result_row[\"init_coms_agreement\"] = normalized_agreement(init_coms[0], \n",
    "                                                             init_coms[1], re)\n",
    "    \n",
    "    result_row[\"init_coms_compat\"] = 1 if dia.are_compatible(init_coms[0], init_coms[1]) else 0\n",
    "    \n",
    "    result_row[\"init_coms_size\"] = sum(coms.size() for coms in init_coms)/len(init_coms)\n",
    "    \n",
    "    # streamlined outputs (results: independent of configuration)\n",
    "            \n",
    "    # initial coms \n",
    "    ic1, ic2 = sub_ex_so_df[\"init_coms\"].unique()     \n",
    "\n",
    "    # streamlined commitments\n",
    "    so_coms1 = [so[1] for so in sub_ex_so_df[sub_ex_so_df[\"init_coms\"]==ic1][\"streamlined_output\"]]\n",
    "    so_coms2 = [so[1] for so in sub_ex_so_df[sub_ex_so_df[\"init_coms\"]==ic2][\"streamlined_output\"]]\n",
    "    \n",
    "    #so_coms1 = set(so_coms1)\n",
    "    #so_coms2 = set(so_coms2)\n",
    "    #so_coms = set(chain(so_coms1, so_coms2))\n",
    "    so_coms = list(chain(so_coms1, so_coms2))\n",
    "    \n",
    "    result_row[\"so_coms_group_agreement\"] = group_normalized_agreement(so_coms1, so_coms2, re)\n",
    "    result_row[\"so_coms_group_compat\"] = group_compatibility(so_coms1, so_coms2, re)\n",
    "    #result_row[\"so_coms_pop_agreement\"] = population_normalized_agreement(so_coms, re)\n",
    "    #result_row[\"so_coms_pop_compat\"] = population_compatibility(so_coms, re)\n",
    "    result_row[\"so_coms_size\"] = sum(coms.size() for coms in so_coms)/len(so_coms)\n",
    "    #result_row[\"so_coms_share\"] = len(so_coms1.intersection(so_coms2))/len(so_coms)\n",
    "    \n",
    "    # steamlined theories\n",
    "    so_thes1 = [so[0] for so in sub_ex_so_df[ sub_ex_so_df[\"init_coms\"]==ic1][\"streamlined_output\"]]\n",
    "    so_thes2 = [so[0] for so in sub_ex_so_df[ sub_ex_so_df[\"init_coms\"]==ic2][\"streamlined_output\"]]\n",
    "    \n",
    "    # closure of so theories\n",
    "    so_thes1 = [dia.closure(so_the) for so_the in so_thes1]\n",
    "    so_thes2 = [dia.closure(so_the) for so_the in so_thes2]\n",
    "    \n",
    "    #so_thes1 = set(so_thes1)\n",
    "    #so_thes2 = set(so_thes2)\n",
    "    #so_thes = set(chain(so_thes1, so_thes2))\n",
    "    so_thes = list(chain(so_thes1, so_thes2))\n",
    "    \n",
    "    result_row[\"so_thes_group_agreement\"] = group_normalized_agreement(so_thes1, so_thes2, re)\n",
    "    result_row[\"so_thes_group_compat\"] = group_compatibility(so_thes1, so_thes2, re)\n",
    "    result_row[\"so_coms_compat_list\"] = compatibility_list(so_coms1, so_coms2, re)\n",
    "    result_row[\"so_coms_simil_list\"] = similarity_list(so_coms1, so_coms2, re)\n",
    "    #result_row[soo_thes_pop_agreement\"] = population_normalized_agreement(so_thes, re)\n",
    "    #result_row[\"so_thes_pop_compat\"] = population_compatibility(so_thes, re)\n",
    "    result_row[\"so_thes_size\"] = sum(the.size() for the in so_thes)/len(so_thes)\n",
    "    #result_row[\"so_thes_share\"] = len(so_thes1.intersection(so_thes2))/len(so_thes)\n",
    "    \n",
    "    # loop through configurations\n",
    "    for config in ex_fp_df[ex_fp_df[\"ds\"]==args][\"configuration\"].unique():\n",
    "\n",
    "        result_row[\"configuration\"] = config     \n",
    "        \n",
    "        # restrict dataframes further\n",
    "        fp_dff = sub_ex_fp_df[sub_ex_fp_df[\"configuration\"]==config]\n",
    "        #go_dff = sub_ex_go_df[sub_ex_go_df[\"configuration\"]==config]\n",
    "\n",
    "        \n",
    "        # fixed points\n",
    "        \n",
    "        #result_row[\"all_fp_full_re\"] = fp_dff[\"fp_full_re_state\"].all()\n",
    "\n",
    "            \n",
    "        # initial coms (identical for go and fp)\n",
    "        ic1, ic2 = fp_dff[\"init_coms\"].unique()\n",
    "        \n",
    "        # fixed points commitments\n",
    "        fp_coms1 = [StandardPosition.from_set(fp[1], n) for fp in fp_dff[fp_dff[\"init_coms\"]==ic1][\"fixed_points\"]]\n",
    "        fp_coms2 = [StandardPosition.from_set(fp[1], n) for fp in fp_dff[fp_dff[\"init_coms\"]==ic2][\"fixed_points\"]]\n",
    "        \n",
    "        #fp_coms1 = set(fp_coms1)\n",
    "        #fp_coms2 = set(fp_coms2)\n",
    "        #fp_coms = set(chain(fp_coms1, fp_coms2))\n",
    "        fp_coms = list(chain(fp_coms1, fp_coms2))\n",
    "        \n",
    "        result_row[\"fp_coms_group_agreement\"] = group_normalized_agreement(fp_coms1, fp_coms2, re)\n",
    "        result_row[\"fp_coms_group_compat\"] = group_compatibility(fp_coms1, fp_coms2, re)\n",
    "        result_row[\"fp_coms_compat_list\"] = compatibility_list(fp_coms1, fp_coms2, re)\n",
    "        result_row[\"fp_coms_simil_list\"] = similarity_list(fp_coms1, fp_coms2, re)\n",
    "        \n",
    "        #result_row[\"fp_coms_pop_agreement\"] = population_normalized_agreement(fp_coms, re)\n",
    "        #result_row[\"fp_coms_pop_compat\"] = population_compatibility(fp_coms, re)\n",
    "        result_row[\"fp_coms_size\"] = sum(coms.size() for coms in fp_coms)/len(fp_coms)\n",
    "        #result_row[\"fp_coms_share\"] = len(fp_coms1.intersection(fp_coms2))/len(fp_coms)\n",
    "        \n",
    "        # fixed points theories\n",
    "        fp_thes1 = [StandardPosition.from_set(fp[0], n) for fp in fp_dff[fp_dff[\"init_coms\"]==ic1][\"fixed_points\"]]\n",
    "        fp_thes2 = [StandardPosition.from_set(fp[0], n) for fp in fp_dff[fp_dff[\"init_coms\"]==ic2][\"fixed_points\"]]\n",
    "        \n",
    "        # closure of fp theories\n",
    "        fp_thes1 = [dia.closure(fp_the) for fp_the in fp_thes1]\n",
    "        fp_thes2 = [dia.closure(fp_the) for fp_the in fp_thes2]\n",
    "        \n",
    "        #fp_thes1 = set(fp_thes1)\n",
    "        #fp_thes2 = set(fp_thes2)\n",
    "        #fp_thes = set(chain(fp_thes1, fp_thes2))\n",
    "        fp_thes = list(chain(fp_thes1, fp_thes2))\n",
    "        \n",
    "        result_row[\"fp_thes_group_agreement\"] = group_normalized_agreement(fp_thes1, fp_thes2, re)\n",
    "        result_row[\"fp_thes_group_compat\"] = group_compatibility(fp_thes1, fp_thes2, re)\n",
    "        #result_row[\"fp_thes_pop_agreement\"] = population_normalized_agreement(fp_thes, re)\n",
    "        #result_row[\"fp_thes_pop_compat\"] = population_compatibility(fp_thes, re)\n",
    "        result_row[\"fp_thes_size\"] = sum(the.size() for the in fp_thes)/len(fp_thes)\n",
    "        #result_row[\"fp_thes_share\"] = len(fp_thes1.intersection(fp_thes2))/len(fp_thes)\n",
    "        \n",
    "        # global optima\n",
    "            \n",
    "        #result_row[\"all_go_full_re\"] = go_dff[\"go_full_re_state\"].all()\n",
    "\n",
    "        # initial coms (identical for go and fp)\n",
    "        #ic1, ic2 = go_dff[\"init_coms\"].unique()     \n",
    "    \n",
    "        # global optima commitments\n",
    "        #go_coms1 = [StandardPosition.from_set(go[1], n) for go in go_dff[go_dff[\"init_coms\"]==ic1][\"global_optima\"]]\n",
    "        #go_coms2 = [StandardPosition.from_set(go[1], n) for go in go_dff[go_dff[\"init_coms\"]==ic2][\"global_optima\"]]\n",
    "        \n",
    "        #go_coms1 = set(go_coms1)\n",
    "        #go_coms2 = set(go_coms2)\n",
    "        #go_coms = set(chain(go_coms1, go_coms2))\n",
    "        #go_coms = list(chain(go_coms1, go_coms2))\n",
    "        \n",
    "        #result_row[\"go_coms_agreement\"] = group_normalized_agreement(go_coms1, go_coms2, re)\n",
    "        #result_row[\"go_coms_compat\"] = group_compatibility(go_coms1, go_coms2, re)\n",
    "        #result_row[\"go_coms_agreement\"] = population_normalized_agreement(go_coms, re)\n",
    "        #result_row[\"go_coms_compat\"] = population_compatibility(go_coms, re)\n",
    "        #result_row[\"go_coms_size\"] = sum(coms.size() for coms in go_coms)/len(go_coms)\n",
    "        #result_row[\"go_coms_share\"] = len(go_coms1.intersection(go_coms2))/len(go_coms)\n",
    "        \n",
    "        # global optima theories\n",
    "        #go_thes1 = [StandardPosition.from_set(go[0], n) for go in go_dff[go_dff[\"init_coms\"]==ic1][\"global_optima\"]]\n",
    "        #go_thes2 = [StandardPosition.from_set(go[0], n) for go in go_dff[go_dff[\"init_coms\"]==ic2][\"global_optima\"]]\n",
    "        \n",
    "        # closure of go theories\n",
    "        #go_thes1 = [dia.closure(go_the) for go_the in go_thes1]\n",
    "        #go_thes2 = [dia.closure(go_the) for go_the in go_thes2]\n",
    "        \n",
    "        #go_thes1 = set(go_thes1)\n",
    "        #go_thes2 = set(go_thes2)\n",
    "        #go_thes = set(chain(go_thes1, go_thes2))\n",
    "        #go_thes = list(chain(go_thes1, go_thes2))\n",
    "        \n",
    "        #result_row[\"go_thes_agreement\"] = group_normalized_agreement(go_thes1, go_thes2, re)\n",
    "        #result_row[\"go_thes_compat\"] = group_compatibility(go_thes1, go_thes2, re)\n",
    "        #result_row[\"go_thes_agreement\"] = population_normalized_agreement(go_thes, re)\n",
    "        #result_row[\"go_thes_compat\"] = population_compatibility(go_thes, re)\n",
    "        #result_row[\"go_thes_size\"] = sum(the.size() for the in go_thes)/len(go_thes)\n",
    "        #result_row[\"go_thes_share\"] = len(go_thes1.intersection(go_thes2))/len(go_thes)\n",
    "\n",
    "        \n",
    "        # append row to dataframe\n",
    "        result_df = result_df.append(result_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fbb7cefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16755, 23)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32b4c53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    16755.000000\n",
       "mean         0.574948\n",
       "std          0.291135\n",
       "min          0.000000\n",
       "25%          0.357143\n",
       "50%          0.571429\n",
       "75%          0.857143\n",
       "max          1.000000\n",
       "Name: fp_coms_group_agreement, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group similarity\n",
    "result_df[\"fp_coms_group_agreement\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a718bd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>init_coms_agreement</th>\n",
       "      <th>ds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.357143</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    init_coms_agreement   ds\n",
       "0              0.071429  130\n",
       "1              0.142857  134\n",
       "2              0.214286  104\n",
       "3              0.285714  115\n",
       "4              0.357143  153\n",
       "5              0.428571  167\n",
       "6              0.500000  154\n",
       "7              0.571429  186\n",
       "8              0.642857  202\n",
       "9              0.714286  202\n",
       "10             0.785714  214\n",
       "11             0.857143  246\n",
       "12             0.928571  275"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.groupby(\"init_coms_agreement\")[\"ds\"].size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "85e95601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init_coms_agreement\n",
       "0.071429    0.285714\n",
       "0.142857    0.321429\n",
       "0.214286    0.357143\n",
       "0.285714    0.428571\n",
       "0.357143    0.428571\n",
       "0.428571    0.500000\n",
       "0.500000    0.500000\n",
       "0.571429    0.642857\n",
       "0.642857    0.714286\n",
       "0.714286    0.785714\n",
       "0.785714    0.928571\n",
       "0.857143    1.000000\n",
       "0.928571    1.000000\n",
       "Name: fp_coms_group_agreement, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.groupby(\"init_coms_agreement\")[\"fp_coms_group_agreement\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4360baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tarfile\n",
    "\n",
    "\n",
    "data_dir = path.join(getcwd(), \"data\")\n",
    "file_name=\"preprocessed_data_two_point_convergence_binned_sp_7_all_configs.csv\"\n",
    "\n",
    "# write results to a .csv.file\n",
    "result_df.to_csv(path.join(data_dir, file_name), index=False)\n",
    "\n",
    "# add to a tar file\n",
    "tar_file = path.join(data_dir, file_name + '.tar.gz')\n",
    "with tarfile.open(tar_file, \"w:gz\") as tar:\n",
    "    tar.add(path.join(data_dir, file_name), recursive=False, arcname=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95fb816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
